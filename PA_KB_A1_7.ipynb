{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT AKHIR KECERDASAN BUATAN\n",
    "#### Kelompok 7 (A1-21)\n",
    "#### Nama Anggota :\n",
    "#### Rezky Nur Sya'ban         (2109106009)\n",
    "#### Andi Nur Fadilah          (2109106015)\n",
    "#### Adlina Safa Sephia Putri  (2109106021)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# Klasifikasi Jenis Sampah\n",
    "* ## Penjelasan DataSet\n",
    "#### Sumber Dataset Klasifikasi Sampah berasal dari Kaggle. Dataset tersebut berisikan gambar berbagai jenis sampah, namun kami hanya mengambil 3 jenis sampah, yaitu kaca, kertas, dan plastik. Data citra tersebut kemudian dibagi menjadi 3 kelas berdasarkan kondisinya, yaitu 'glass', 'paper', dan 'plastic' ke dalam folder yang terpisah, yakni train, test, dan val dengan perbandingan 7:1:2.\n",
    "\n",
    "* ## Penjelasan Project\n",
    "#### Projek akhir ini membahas mengenai model kecerdasan buatan dalam Pemilahan sampah yang melibatkan pemisahan sampah menurut cara penanganan atau pengolahannya. Penting untuk didaur ulang karena beberapa bahan dapat didaur ulang dan yang lainnya tidak.\n",
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mengimport Library yang Dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Sequential, layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "##### Memisahkan dataset ke dalam beberapa folder: train, test, dan val dengan porsi 70 : 10 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitfolders.ratio(\"Garbage classification/Garbage classification/\", output = \"Klasifikasi Sampah\", seed = 1337, ratio = (.7, .1, .2), group_prefix = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memuat Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = image_dataset_from_directory(\n",
    "    'Klasifikasi Sampah/train/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    image_size = (100, 100),\n",
    "    shuffle = True, \n",
    "    seed = 47,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = image_dataset_from_directory(\n",
    "    'Klasifikasi Sampah/val/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    image_size = (100, 1000),\n",
    "    shuffle = True, \n",
    "    seed = 47,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = image_dataset_from_directory(\n",
    "    'Klasifikasi Sampah/test/',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    image_size = (100, 100),\n",
    "    shuffle = True, \n",
    "    seed = 47,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Klasifikasi Sampah/train/'\n",
    "test_dir = 'Klasifikasi Sampah/test/'\n",
    "val_dir = 'Klasifikasi Sampah/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.1\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    seed=0\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Visualisasi Augmentasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    img, label = train_generator.next()\n",
    "    plt.imshow(img[0])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analyst dan Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nama_dataset = \"Garbage Classification\"\n",
    "sumber = \"https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification\"\n",
    "class_names = dataset_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------------- I N F O R M A S I    D A T A S E T --------------------------\")\n",
    "print(\"Nama Dataset    : \", nama_dataset)\n",
    "print(\"Sumber          : \", sumber)\n",
    "print(\"Kelas           : \", dataset_train.class_names)\n",
    "print(\"Jumlah Kelas    : \", len(dataset_train.class_names))\n",
    "print(\"Ukuran Gambar   : \", (images.shape))\n",
    "print(\"----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Visualisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pratinjau Gambar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for images, labels in dataset_train.take(1):\n",
    "    for i in range (25):\n",
    "        ax = plt.subplot(5, 5, i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset_train.unbatch()\n",
    "labels = []\n",
    "for x, y in train:\n",
    "    index = y\n",
    "    labels.append(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "sns.countplot(x = labels)\n",
    "plt.title(\"Jumlah Data Training pada Setiap Jenis Sampah\")\n",
    "plt.xlabel(\"Jenis Sampah\")\n",
    "plt.ylabel(\"Jumlah\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset_test.unbatch()\n",
    "labels = []\n",
    "for x, y in test:\n",
    "    index = y\n",
    "    labels.append(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "sns.countplot(x = labels)\n",
    "plt.title(\"Jumlah Data Testing pada Setiap Jenis Sampah\")\n",
    "plt.xlabel(\"Jenis Sampah\")\n",
    "plt.ylabel(\"Jumlah\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = dataset_val.unbatch()\n",
    "labels = []\n",
    "for x, y in validation:\n",
    "    index = y\n",
    "    labels.append(class_names[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "sns.countplot(x = labels)\n",
    "plt.title(\"Jumlah Data Validation pada Setiap Jenis Sampah\")\n",
    "plt.xlabel(\"Jenis Sampah\")\n",
    "plt.ylabel(\"Jumlah\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('loss') < 1e-4):\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "cb = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = model.fit_generator(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=60, \n",
    "                    verbose = 1,  \n",
    "                    callbacks = cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_evaluate = model.evaluate(dataset_test,verbose =0)\n",
    "\n",
    "# print(f'Test loss     : {test_evaluate[0]}')\n",
    "# print(f'Test accuracy : {round(test_evaluate[1],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membandingkan perkembangan epoch Train vs. Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [i+1 for i in range(60)]\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.suptitle('Train vs. Validation Accuracy')\n",
    "\n",
    "# Subplot Akurasi\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(x = epoch, y = hasil.history['accuracy'], label = 'Akurasi Training')\n",
    "sns.lineplot(x = epoch, y = hasil.history['val_accuracy'], label = 'Akurasi Validation')\n",
    "\n",
    "plt.xticks(epoch)\n",
    "plt.xlabel('N_Epoch')\n",
    "plt.ylabel('Accuracy(%)')\n",
    "plt.title('Akurasi Train/Validation')\n",
    "\n",
    "#Subplot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x = epoch, y = hasil.history['loss'], label = 'Loss Training')\n",
    "sns.lineplot(x = epoch, y = hasil.history['val_loss'], label = 'Loss Validation')\n",
    "\n",
    "plt.xticks(epoch)\n",
    "plt.xlabel('N_Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Train/Validation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pratinjau Hasil Prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi Gambar yang Diprediksi Benar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(dataset_test))\n",
    "\n",
    "plt.figure(figsize = (16, 16))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    y_pred = np.argmax(model.predict(image[i][None, ...]))\n",
    "    plt.imshow(tf.squeeze(image[i].numpy().astype(\"uint8\")), cmap = 'gray')\n",
    "    plt.title(f'label : {class_names[label[i]]}, predict: {class_names[y_pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pratinjau Kesalahan Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "i, j = 0, 0\n",
    "while (j < 12):\n",
    "    TrueLabel = class_names[np.argmax(label[i])]\n",
    "    plt.subplot(3,4,j +1)\n",
    "    plt.axis('off')\n",
    "    y_pred = np.argmax(model.predict(image[i][None,...],verbose=0))\n",
    "\n",
    "    if (TrueLabel != class_names[y_pred]):\n",
    "        plt.imshow(tf.squeeze(image[i].numpy().astype(\"uint8\")),cmap='gray')\n",
    "        plt.title(f'label: {TrueLabel}, predict : {class_names[y_pred]}')\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Menyimpan model dalam format SavedModel\n",
    "export_dir = 'saved_model/'\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SavedModel menjadi model.tflite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    " \n",
    "tflite_model_file = pathlib.Path('model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
